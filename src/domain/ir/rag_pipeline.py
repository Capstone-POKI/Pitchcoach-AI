import json
import os
import re
from math import sqrt
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from src.infrastructure.embedding.client import EmbeddingClient
from src.infrastructure.gemini.client import GeminiJSONClient


DEFAULT_TOP_K = 3
SIM_HIGH = 0.72
SIM_MID = 0.60
DEFAULT_LLM_SLIDE_LIMIT = 12
GROUP_CATEGORY_PRIORS = {
    "PROBLEM": {"PROBLEM", "MARKET"},
    "SOLUTION": {"SOLUTION", "PRODUCT"},
    "MARKET_BM": {"MARKET", "BUSINESS_MODEL", "COMPETITION"},
    "TRACTION": {"TRACTION", "MARKET"},
    "TEAM": {"TEAM"},
    "FINANCE": {"FINANCE", "BUSINESS_MODEL"},
}

CATEGORY_KEYWORDS = {
    "PROBLEM": [
        "ë¬¸ì œ",
        "pain",
        "ë¶ˆí¸",
        "í•œê³„",
        "ë¦¬ìŠ¤í¬",
        "ì™œ í•„ìš”í•œ",
        "ë‹ˆì¦ˆ",
        "í˜„í™©",
    ],
    "SOLUTION": [
        "í•´ê²°",
        "ì†”ë£¨ì…˜",
        "solution",
        "as-is",
        "to-be",
        "ê°œì„ ",
        "ì œì•ˆ",
        "approach",
    ],
    "PRODUCT": [
        "ì œí’ˆ",
        "í”„ë¡œì„¸ìŠ¤",
        "ì•„í‚¤í…ì²˜",
        "ui",
        "ux",
        "í™”ë©´",
        "ì¸í„°í˜ì´ìŠ¤",
        "ìŠ¤í¬ë¦°ìƒ·",
        "ë°ëª¨",
        "flow",
        "ì‘ë™ ë°©ì‹",
        "ì‚¬ìš© íë¦„",
        "ì‚¬ìš©ì ì—¬ì •",
        "ì‹œì—°",
    ],
    "MARKET": [
        "tam",
        "sam",
        "som",
        "ì‹œì¥",
        "ì‹œì¥ê·œëª¨",
        "cagr",
        "ì„±ì¥ë¥ ",
        "ìˆ˜ìš”",
        "ê³ ê°ìˆ˜",
    ],
    "BUSINESS_MODEL": [
        "ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸",
        "bm",
        "ìˆ˜ìµ",
        "ìˆ˜ìˆ˜ë£Œ",
        "êµ¬ë…",
        "pricing",
        "ltv",
        "arpu",
        "arr",
        "unit economics",
    ],
    "TRACTION": [
        "mou",
        "loi",
        "poc",
        "ë§¤ì¶œ",
        "ì‹¤ë§¤ì¶œ",
        "mrr",
        "arr",
        "í™œì„± ì‚¬ìš©ì",
        "mau",
        "dau",
        "ëŸ°ì¹­",
        "ë² íƒ€",
        "íŒŒì¼ëŸ¿",
        "ê³„ì•½",
        "ì¬ê³„ì•½",
        "ì„ ì •",
        "ì¸ì¦",
        "íŠ¹í—ˆ ë“±ë¡",
        "ê³ ê°ì‚¬",
        "ì§€í‘œ",
    ],
    "COMPETITION": [
        "ê²½ìŸ",
        "ê²½ìŸì‚¬",
        "ì°¨ë³„",
        "ë¹„êµ",
        "í¬ì§€ì…”ë‹",
        "moat",
    ],
    "TEAM": [
        "íŒ€",
        "ceo",
        "cto",
        "coo",
        "cso",
        "cmo",
        "founder",
        "ìë¬¸",
        "ê²½ë ¥",
        "í•™ë ¥",
    ],
    "FINANCE": [
        "ì¬ë¬´",
        "ì†ìµ",
        "bep",
        "burn",
        "runway",
        "íˆ¬ì",
        "ìê¸ˆ",
        "cashflow",
        "ipo",
    ],
    "ASK": [
        "ë¡œë“œë§µ",
        "roadmap",
        "ê³„íš",
        "milestone",
        "ë§ˆì¼ìŠ¤í†¤",
        "phase",
        "ì¼ì •",
        "ë¶„ê¸°",
        "q1",
        "q2",
        "q3",
        "q4",
        "2026",
        "2027",
        "2028",
        "next step",
        "ìš”ì²­",
        "ë¬¸ì˜",
    ],
}

CATEGORY_PRIORITY = [
    "TRACTION",
    "FINANCE",
    "BUSINESS_MODEL",
    "MARKET",
    "TEAM",
    "COMPETITION",
    "SOLUTION",
    "PRODUCT",
    "PROBLEM",
    "ASK",
    "COVER",
    "OTHER",
]

_PIPELINE_CONFIG_CACHE: Optional[Dict[str, Any]] = None


def _load_pipeline_config() -> Dict[str, Any]:
    global _PIPELINE_CONFIG_CACHE
    if _PIPELINE_CONFIG_CACHE is not None:
        return _PIPELINE_CONFIG_CACHE
    default_path = Path("data/config/pitchcoach_pipeline_config.json")
    cfg_path = Path(os.getenv("PITCHCOACH_PIPELINE_CONFIG_PATH", str(default_path)))
    if cfg_path.exists():
        try:
            _PIPELINE_CONFIG_CACHE = json.loads(cfg_path.read_text(encoding="utf-8"))
            return _PIPELINE_CONFIG_CACHE
        except Exception:
            pass
    _PIPELINE_CONFIG_CACHE = {}
    return _PIPELINE_CONFIG_CACHE


def _sim_high() -> float:
    cfg = _load_pipeline_config()
    cfg_val = (
        cfg.get("matching", {})
        .get("similarity_threshold", {})
        .get("high", SIM_HIGH)
    )
    try:
        return float(os.getenv("IR_SIM_HIGH", str(cfg_val)))
    except Exception:
        return SIM_HIGH


def _sim_mid() -> float:
    cfg = _load_pipeline_config()
    cfg_val = (
        cfg.get("matching", {})
        .get("similarity_threshold", {})
        .get("mid", SIM_MID)
    )
    try:
        return float(os.getenv("IR_SIM_MID", str(cfg_val)))
    except Exception:
        return SIM_MID


def _sim_low() -> float:
    cfg = _load_pipeline_config()
    cfg_val = cfg.get("matching", {}).get("similarity_threshold", {}).get("low")
    if cfg_val is None:
        cfg_val = max(0.0, _sim_mid() - 0.10)
    try:
        return float(os.getenv("IR_SIM_LOW", str(cfg_val)))
    except Exception:
        return max(0.0, _sim_mid() - 0.10)


def _top_k() -> int:
    cfg = _load_pipeline_config()
    cfg_val = cfg.get("matching", {}).get("top_k", DEFAULT_TOP_K)
    try:
        v = int(os.getenv("IR_TOP_K", str(cfg_val)))
        return max(1, min(10, v))
    except Exception:
        return DEFAULT_TOP_K


def run_rag_ir_analysis(
    docai_result: Dict[str, Any],
    output_path: str,
    strategy: Optional[Dict[str, Any]] = None,
    analysis_version: int = 1,
    pitch_type: Optional[str] = None,
) -> Dict[str, Any]:
    if not docai_result:
        raise RuntimeError("OCR ê²°ê³¼ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")

    print("ğŸ§  [RAG] ë¶„ì„ ì—”ì§„ ì‹œì‘")
    gemini = GeminiJSONClient()
    slides = _build_slides(docai_result)
    pitch_type = _resolve_pitch_type(strategy, pitch_type, slides)
    rubric = _load_rubric(pitch_type)
    print(f"ğŸ§¾ [RAG] ìŠ¬ë¼ì´ë“œ ë¡œë“œ ì™„ë£Œ: {len(slides)}ì¥")

    print("ğŸ·ï¸ [RAG] ìŠ¬ë¼ì´ë“œ ë¶„ë¥˜/ìš”ì•½ ì§„í–‰")
    _classify_and_summarize_slides(slides, gemini)

    print("ğŸ”¢ [RAG] ì„ë² ë”© ìƒì„± ì§„í–‰")
    embed_client = _init_embedding_client()
    _embed_slides(slides, embed_client)
    _embed_rubric_items(rubric, embed_client)

    print("ğŸ“š [RAG] ë£¨ë¸Œë¦­ ë§¤ì¹­ ë° ê¸°ì¤€ë³„ ì ìˆ˜ ê³„ì‚°")
    criteria_scores = _score_criteria_with_rag(
        slides=slides,
        rubric=rubric,
        gemini=gemini,
    )

    print("ğŸ§© [RAG] ì¢…í•© ì ìˆ˜/ê°€ì´ë“œ ìƒì„±")
    deck_score = _build_deck_score(criteria_scores, rubric, strategy, gemini)
    presentation_guide = _build_presentation_guide(slides, criteria_scores, strategy)
    slide_cards = _build_slide_cards(slides, criteria_scores)

    final_output: Dict[str, Any] = {
        "analysis_version": analysis_version,
        "analysis_method": "RAG+LLM" if gemini.model else "RAG+RuleBased",
        "pitch_type": pitch_type,
        "deck_score": deck_score,
        "criteria_scores": criteria_scores,
        "presentation_guide": presentation_guide,
        "slides": slide_cards,
        "meta": {
            "filename": docai_result.get("metadata", {}).get("filename", "unknown"),
            "total_slides": len(slides),
            "analysis_model": gemini.model_name if gemini.model else None,
            "embedding_model": "gemini-embedding-001",
        },
    }

    output_file = Path(output_path)
    output_file.parent.mkdir(parents=True, exist_ok=True)
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)

    print("âœ… [RAG] ìµœì¢… JSON ìƒì„± ì™„ë£Œ")
    return final_output


def _resolve_pitch_type(
    strategy: Optional[Dict[str, Any]],
    explicit_pitch_type: Optional[str],
    slides: Optional[List[Dict[str, Any]]] = None,
) -> str:
    if explicit_pitch_type:
        mapped = _normalize_pitch_type(explicit_pitch_type)
        if mapped:
            return mapped

    if not strategy:
        inferred = _infer_pitch_type_from_slides(slides or [])
        return inferred or "VC_DEMO"
    raw = str(strategy.get("type", "")).lower()
    if "government" in raw or "ì •ë¶€" in raw or "grant" in raw:
        return "GOV_SUPPORT"
    if "competition" in raw or "ê²½ì§„" in raw:
        return "STARTUP_CONTEST"
    return "VC_DEMO"


def _normalize_pitch_type(value: str) -> Optional[str]:
    v = value.strip().upper()
    mapping = {
        "VC_DEMO": "VC_DEMO",
        "GOVERNMENT": "GOV_SUPPORT",
        "GOV_SUPPORT": "GOV_SUPPORT",
        "STARTUP_CONTEST": "STARTUP_CONTEST",
        "COMPETITION": "STARTUP_CONTEST",
        # Elevator pitch is closest to short-form VC story in current v1 rubric set.
        "ELEVATOR": "VC_DEMO",
    }
    return mapping.get(v)


def _infer_pitch_type_from_slides(slides: List[Dict[str, Any]]) -> Optional[str]:
    text = " ".join((s.get("clean_text", "") or "") for s in slides[:10]).lower()
    if not text:
        return None

    gov_keywords = ["ì •ë¶€", "ì§€ì›ì‚¬ì—…", "ì •ì±…", "ì§€ìì²´", "ê³µê³µ", "ê³¼ì œ", "k-startup", "ì°½ì—…íŒ¨í‚¤ì§€"]
    comp_keywords = ["ê²½ì§„ëŒ€íšŒ", "contest", "í•´ì»¤í†¤", "ìˆ˜ìƒ", "ë°ëª¨ë°ì´ ì™¸ ëŒ€íšŒ"]

    gov_hits = sum(1 for k in gov_keywords if k in text)
    comp_hits = sum(1 for k in comp_keywords if k in text)

    if gov_hits >= 2:
        return "GOV_SUPPORT"
    if comp_hits >= 2:
        return "STARTUP_CONTEST"
    return "VC_DEMO"


def _build_slides(docai_result: Dict[str, Any]) -> List[Dict[str, Any]]:
    pages = docai_result.get("pages", [])
    detected_sections = docai_result.get("detected_sections", [])
    section_map = {s.get("page"): s.get("section", "unknown") for s in detected_sections if isinstance(s, dict)}
    full_text = docai_result.get("text", "")

    slides: List[Dict[str, Any]] = []
    for idx, page in enumerate(pages):
        page_num = idx + 1
        page_text = _extract_page_text(page, full_text).strip()
        slides.append(
            {
                "slide_number": page_num,
                "raw_text": page_text,
                "clean_text": _clean_text(page_text),
                "short_summary": "",
                "key_claims": [],
                "category": section_map.get(page_num, "OTHER").upper(),
                "category_confidence": 0.5,
                "text_deficiency_flag": len(page_text) < 20,
                "embedding": [],
            }
        )
    return slides


def _extract_page_text(page: Dict[str, Any], full_text: str) -> str:
    parts: List[str] = []
    for block in page.get("blocks", []):
        layout = block.get("layout", {})
        for segment in layout.get("textAnchor", {}).get("textSegments", []):
            start = int(segment.get("startIndex", 0))
            end = int(segment.get("endIndex", 0))
            parts.append(full_text[start:end])
    return " ".join(parts)


def _clean_text(text: str) -> str:
    text = re.sub(r"\s+", " ", text or "").strip()
    return text


def _classify_and_summarize_slides(slides: List[Dict[str, Any]], gemini: GeminiJSONClient) -> None:
    llm_slide_limit = int(os.getenv("IR_LLM_SLIDE_LIMIT", str(DEFAULT_LLM_SLIDE_LIMIT)))
    use_llm_count = min(len(slides), llm_slide_limit) if gemini.model else 0
    if gemini.model:
        print(f"   - Gemini ë¶„ë¥˜ ëŒ€ìƒ: {use_llm_count}/{len(slides)}ì¥ (ë‚˜ë¨¸ì§€ ê·œì¹™ ê¸°ë°˜)")

    for idx, slide in enumerate(slides, start=1):
        if idx % 5 == 0 or idx == len(slides):
            print(f"   - ë¶„ë¥˜ ì§„í–‰: {idx}/{len(slides)}")
        if not slide["clean_text"]:
            slide["short_summary"] = "í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ëŠ” ìŠ¬ë¼ì´ë“œì…ë‹ˆë‹¤."
            slide["key_claims"] = []
            slide["category"], slide["category_confidence"] = "OTHER", 0.2
            continue

        if gemini.model and idx <= use_llm_count:
            try:
                prompt = (
                    "ë‹¤ìŒ IR ìŠ¬ë¼ì´ë“œë¥¼ ë¶„ì„í•´ì„œ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”.\n"
                    "categoryëŠ” COVER|PROBLEM|SOLUTION|PRODUCT|MARKET|BUSINESS_MODEL|TRACTION|"
                    "COMPETITION|TEAM|FINANCE|ASK|OTHER ì¤‘ í•˜ë‚˜.\n"
                    "ì¶œë ¥: {\"category\":\"...\",\"category_confidence\":0.0~1.0,"
                    "\"short_summary\":\"...\",\"key_claims\":[\"...\", \"...\"]}\n\n"
                    f"[ìŠ¬ë¼ì´ë“œ í…ìŠ¤íŠ¸]\n{slide['clean_text'][:4000]}"
                )
                out = gemini.generate_json(prompt, temperature=0.1)
                category = str(out.get("category", "OTHER")).upper()
                if category not in {
                    "COVER",
                    "PROBLEM",
                    "SOLUTION",
                    "PRODUCT",
                    "MARKET",
                    "BUSINESS_MODEL",
                    "TRACTION",
                    "COMPETITION",
                    "TEAM",
                    "FINANCE",
                    "ASK",
                    "OTHER",
                }:
                    category = "OTHER"
                slide["category"] = category
                slide["category_confidence"] = _clamp01(float(out.get("category_confidence", 0.7)))
                slide["short_summary"] = str(out.get("short_summary", ""))[:280] or slide["clean_text"][:180]
                claims = out.get("key_claims", [])
                if isinstance(claims, list):
                    slide["key_claims"] = [str(c).strip() for c in claims if str(c).strip()][:5]
                else:
                    slide["key_claims"] = []
                continue
            except Exception:
                pass

        # Fallback classification and summary
        category, conf = _keyword_classify_with_confidence(
            slide["clean_text"],
            slide_number=int(slide.get("slide_number", 0)),
            total_slides=len(slides),
        )
        slide["category"] = category
        slide["category_confidence"] = conf
        slide["short_summary"] = slide["clean_text"][:180]
        slide["key_claims"] = _extract_claims(slide["clean_text"])


def _keyword_classify(text: str) -> str:
    return _keyword_classify_with_confidence(text)[0]


def _keyword_classify_with_confidence(
    text: str,
    slide_number: int = 0,
    total_slides: int = 0,
) -> Tuple[str, float]:
    t = (text or "").lower()
    if not t.strip():
        return "OTHER", 0.2
    token_count = len(re.findall(r"[a-zA-Z0-9ê°€-í£]+", t))
    line_count = len([ln for ln in re.split(r"[\r\n]+", t) if ln.strip()])
    num_cnt = len(re.findall(r"\d", t))

    has_market_core = any(k in t for k in ["tam", "sam", "som", "ì‹œì¥ê·œëª¨", "cagr", "ì„±ì¥ë¥ ", "ì‹œì¥ ì ìœ ", "ì‹œì¥ ì„±ì¥"])
    has_plan_core = any(k in t for k in ["ë¡œë“œë§µ", "roadmap", "ë§ˆì¼ìŠ¤í†¤", "q1", "q2", "q3", "q4", "2026", "2027", "2028", "ì¼ì •", "ë¶„ê¸°"])
    has_traction_core = any(k in t for k in ["mou", "loi", "poc", "ê³„ì•½", "ì„ ì •", "ì¸ì¦", "ì‹¤ë§¤ì¶œ", "mrr", "arr", "ì¬ê³„ì•½", "íŒŒì¼ëŸ¿", "ë² íƒ€"])
    has_product_core = any(k in t for k in ["ui", "ux", "í™”ë©´", "ìŠ¤í¬ë¦°ìƒ·", "ë°ëª¨", "í”„ë¡œì„¸ìŠ¤", "flow", "ì›Œí¬í”Œë¡œìš°", "ì•„í‚¤í…ì²˜"])
    has_solution_core = any(k in t for k in ["í•´ê²°", "ì†”ë£¨ì…˜", "ê°œì„ ", "ì œì•ˆ", "ëŒ€ì•ˆ", "íš¨ê³¼", "as-is", "to-be"])
    has_team_core = any(k in t for k in ["ceo", "cto", "coo", "cmo", "founder", "íŒ€", "ë©¤ë²„", "í”„ë¡œí•„", "ê²½ë ¥", "í•™ë ¥"])
    has_cover_core = any(k in t for k in ["thank", "thanks", "q&a", "ê°ì‚¬", "ë¬¸ì˜", "logo", "chapter", "section", "part", "overview", "agenda"])

    # Cover/title slide heuristic
    if total_slides > 0:
        if slide_number == 1 and token_count <= 40:
            return "COVER", 0.82
        if slide_number == total_slides and token_count <= 60:
            return "COVER", 0.80
    if len(t) < 130 and any(k in t for k in ["ir", "pitch", "ë°œí‘œ", "ë°í¬", "deck"]):
        return "COVER", 0.78
    if has_cover_core and token_count <= 20 and line_count <= 4 and num_cnt == 0:
        return "COVER", 0.70
    if token_count <= 10 and num_cnt == 0 and not (has_market_core or has_traction_core or has_product_core or has_solution_core or has_team_core):
        return "COVER", 0.66
    if total_slides > 0 and slide_number <= 2 and has_team_core:
        return "TEAM", 0.70

    scores: Dict[str, float] = {k: 0.0 for k in CATEGORY_KEYWORDS}
    for category, keywords in CATEGORY_KEYWORDS.items():
        for kw in keywords:
            if kw in t:
                scores[category] += 1.0

    if num_cnt >= 8:
        scores["MARKET"] += 1.0
        scores["BUSINESS_MODEL"] += 0.9
        scores["TRACTION"] += 0.7
    if has_market_core:
        scores["MARKET"] += 1.0
    else:
        scores["MARKET"] -= 0.6
    if has_plan_core:
        scores["ASK"] += 1.1
        scores["TRACTION"] -= 0.4
    if has_traction_core:
        scores["TRACTION"] += 1.2
        scores["PROBLEM"] -= 0.3
    if has_product_core:
        scores["PRODUCT"] += 1.2
        if has_plan_core:
            scores["PRODUCT"] += 0.4
            scores["ASK"] -= 0.3
    if has_solution_core:
        scores["SOLUTION"] += 1.2
        if not has_product_core:
            scores["PRODUCT"] -= 0.5
    if has_team_core:
        scores["TEAM"] += 1.4
        scores["TRACTION"] -= 0.4
        scores["SOLUTION"] -= 0.3

    # Prefer solution for problem->solution storytelling slides.
    if has_solution_core and any(k in t for k in ["ë¬¸ì œ", "pain", "ë¶ˆí¸", "í•œê³„", "ì°¨ë³„"]):
        scores["SOLUTION"] += 0.6
        scores["PROBLEM"] += 0.3

    best_score = max(scores.values()) if scores else 0.0
    if best_score < 1.0:
        return "OTHER", 0.35

    top = [c for c, s in scores.items() if s == best_score]
    conf = _clamp01(0.45 + min(0.40, best_score / 9.0))
    for c in CATEGORY_PRIORITY:
        if c in top:
            return c, conf
    return (top[0], conf) if top else ("OTHER", 0.35)


def _extract_claims(text: str) -> List[str]:
    chunks = re.split(r"[.!?\n]", text)
    claims = [c.strip() for c in chunks if len(c.strip()) >= 15]
    return claims[:5]


def _init_embedding_client() -> Optional[EmbeddingClient]:
    if os.getenv("ENABLE_VERTEX_EMBEDDING") != "1":
        return None
    try:
        project_id = os.getenv("PROJECT_ID")
        if not project_id:
            return None
        client = EmbeddingClient(model_name="gemini-embedding-001")
        client.init_vertex(project_id=project_id, location=os.getenv("LOCATION", "us-central1"))
        return client
    except Exception:
        return None


def _embed_slides(slides: List[Dict[str, Any]], embed_client: Optional[EmbeddingClient]) -> None:
    texts = [f"{s['clean_text']}\n{s['short_summary']}" for s in slides]
    vectors = _embed_texts(texts, embed_client)
    for slide, vec in zip(slides, vectors):
        slide["embedding"] = vec


def _load_rubric(pitch_type: str) -> Dict[str, Any]:
    path = os.getenv("PITCHCOACH_RUBRIC_PATH")
    if path:
        p = Path(path)
        if p.exists():
            try:
                data = json.loads(p.read_text(encoding="utf-8"))
                rubric = data.get("rubrics", {}).get(pitch_type)
                if rubric:
                    return rubric
            except Exception:
                pass
    return _default_rubric(pitch_type)


def _default_rubric(pitch_type: str) -> Dict[str, Any]:
    common = [
        {
            "group_id": "PROBLEM",
            "group_name": "ë¬¸ì œì •ì˜",
            "group_weight": 0.2,
            "max_score": 20,
            "items": [
                {"item_id": "PR_01", "item_name": "êµ¬ì²´ì  ë¬¸ì œ ì •ì˜", "description": "ë¬¸ì œë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì •ì˜", "max_score": 10, "fail_if_missing": True},
                {"item_id": "PR_02", "item_name": "ê²€ì¦ ê·¼ê±°", "description": "ê³ ê° ë‹ˆì¦ˆ/ë°ì´í„° ê·¼ê±°", "max_score": 10, "fail_if_missing": False},
            ],
        },
        {
            "group_id": "SOLUTION",
            "group_name": "ì†”ë£¨ì…˜",
            "group_weight": 0.2,
            "max_score": 20,
            "items": [
                {"item_id": "SO_01", "item_name": "í•´ê²°ì±… ëª…í™•ì„±", "description": "í•´ê²°ì±…ì˜ êµ¬ì²´ì„±", "max_score": 10, "fail_if_missing": True},
                {"item_id": "SO_02", "item_name": "ì°¨ë³„í™”", "description": "ê²½ìŸ ëŒ€ë¹„ ì°¨ë³„ í¬ì¸íŠ¸", "max_score": 10, "fail_if_missing": False},
            ],
        },
        {
            "group_id": "MARKET_BM",
            "group_name": "ì‹œì¥/ë¹„ì¦ˆë‹ˆìŠ¤",
            "group_weight": 0.25,
            "max_score": 25,
            "items": [
                {"item_id": "MK_01", "item_name": "ì‹œì¥ê·œëª¨", "description": "TAM/SAM/SOM ë“± ì‹œì¥ ê·œëª¨", "max_score": 10, "fail_if_missing": False},
                {"item_id": "MK_02", "item_name": "ìˆ˜ìµëª¨ë¸", "description": "BM/ê°€ê²©/ìˆ˜ìµì‹", "max_score": 15, "fail_if_missing": True},
            ],
        },
        {
            "group_id": "TRACTION",
            "group_name": "ì‹¤ì ",
            "group_weight": 0.15,
            "max_score": 15,
            "items": [
                {"item_id": "TR_01", "item_name": "ê²€ì¦ì§€í‘œ", "description": "ë² íƒ€/ì‚¬ìš©ì/ë§¤ì¶œ ì§€í‘œ", "max_score": 15, "fail_if_missing": False},
            ],
        },
        {
            "group_id": "TEAM",
            "group_name": "íŒ€",
            "group_weight": 0.1,
            "max_score": 10,
            "items": [
                {"item_id": "TE_01", "item_name": "íŒ€ ì—­ëŸ‰", "description": "ëŒ€í‘œ/í•µì‹¬íŒ€ ì—­ëŸ‰", "max_score": 10, "fail_if_missing": False},
            ],
        },
        {
            "group_id": "FINANCE",
            "group_name": "ìê¸ˆ ê³„íš",
            "group_weight": 0.1,
            "max_score": 10,
            "items": [
                {"item_id": "FI_01", "item_name": "ìê¸ˆ í™œìš© ê³„íš", "description": "ìê¸ˆ ë°°ë¶„ê³¼ ê³„íš", "max_score": 10, "fail_if_missing": False},
            ],
        },
    ]
    return {"pitch_type": pitch_type, "total_points": 100, "groups": common}


def _embed_rubric_items(rubric: Dict[str, Any], embed_client: Optional[EmbeddingClient]) -> None:
    items = []
    refs: List[Dict[str, Any]] = []
    for group in rubric.get("groups", []):
        for item in group.get("items", []):
            text = f"{item.get('item_name', '')}. {item.get('description', '')}"
            items.append(text)
            refs.append(item)
    vectors = _embed_texts(items, embed_client)
    for item, vec in zip(refs, vectors):
        item["embedding"] = vec


def _embed_texts(texts: List[str], embed_client: Optional[EmbeddingClient]) -> List[List[float]]:
    if embed_client is not None:
        try:
            return embed_client.embed(texts, task_type="RETRIEVAL_DOCUMENT")
        except Exception:
            pass
    return [_fallback_embed(t) for t in texts]


def _fallback_embed(text: str) -> List[float]:
    # Lightweight deterministic fallback embedding.
    vec = [0.0] * 64
    for token in re.findall(r"[a-zA-Z0-9ê°€-í£_]+", text.lower()):
        idx = hash(token) % len(vec)
        vec[idx] += 1.0
    norm = sqrt(sum(v * v for v in vec)) or 1.0
    return [v / norm for v in vec]


def _score_criteria_with_rag(
    slides: List[Dict[str, Any]],
    rubric: Dict[str, Any],
    gemini: GeminiJSONClient,
) -> List[Dict[str, Any]]:
    criteria_scores: List[Dict[str, Any]] = []

    for group in rubric.get("groups", []):
        group_items = group.get("items", [])
        raw_group_score = 0.0
        raw_group_max = float(group.get("max_score", 0))
        all_related: List[int] = []
        missing_items: List[Dict[str, str]] = []
        coverage_values: List[str] = []
        coverage_weights: List[float] = []
        evidence_for_group: List[Dict[str, Any]] = []

        for item in group_items:
            evidences = _retrieve_top_k(
                item,
                slides,
                top_k=_top_k(),
                group_id=str(group.get("group_id", "")),
            )
            max_sim = evidences[0]["similarity"] if evidences else 0.0
            coverage = _decide_coverage(item, evidences, gemini)
            item_max = float(item.get("max_score", 0))
            item_score = _score_item(item_max, coverage, max_sim)

            raw_group_score += item_score
            coverage_values.append(coverage)
            coverage_weights.append(item_max)
            # Bind evidence to score: for covered/partial items, keep at least top evidence.
            if coverage in {"COVERED", "PARTIALLY_COVERED"} and evidences:
                all_related.append(int(evidences[0]["slide_number"]))
                all_related.extend([e["slide_number"] for e in evidences[1:] if e["similarity"] >= (_sim_mid() - 0.1)])
            evidence_for_group.append(
                {
                    "item_id": item.get("item_id"),
                    "item_name": item.get("item_name"),
                    "coverage": coverage,
                    "max_similarity": max_sim,
                    "related_slides": [e["slide_number"] for e in evidences],
                    "top_summary": (evidences[0]["summary"] if evidences else ""),
                }
            )

            if coverage in {"NOT_COVERED", "PARTIALLY_COVERED"}:
                missing_items.append(
                    {
                        "item_id": item.get("item_id", ""),
                        "item_name": item.get("item_name", ""),
                        "suggestion": _build_missing_suggestion(item, coverage),
                    }
                )

        related_unique = sorted(set(all_related))
        if raw_group_score > 0 and not related_unique:
            fallback_related: List[int] = []
            for ev in evidence_for_group:
                rel = ev.get("related_slides", [])
                if rel:
                    fallback_related.append(int(rel[0]))
            related_unique = sorted(set(fallback_related))
        group_coverage = _reduce_group_coverage(coverage_values, coverage_weights)
        score_100 = int(round((raw_group_score / raw_group_max) * 100)) if raw_group_max > 0 else 0
        feedback, confidence = _build_group_feedback(
            group=group,
            evidence_for_group=evidence_for_group,
            missing_items=missing_items,
            gemini=gemini,
        )

        criteria_scores.append(
            {
                "criteria_score_id": f"cs-{group.get('group_id', '').lower()}",
                "criteria_id": group.get("group_id"),
                "criteria_name": group.get("group_name"),
                "pitchcoach_interpretation": _group_interpretation(group),
                "raw_score": round(raw_group_score, 2),
                "raw_max_score": raw_group_max,
                "score": max(0, min(100, score_100)),
                "max_score": 100,
                "is_covered": group_coverage != "NOT_COVERED",
                "coverage_status": group_coverage,
                "feedback": feedback,
                "related_slides": related_unique,
                "missing_items": missing_items,
                "confidence": confidence,
            }
        )
    return _validate_and_repair_criteria(criteria_scores)


def _build_missing_suggestion(item: Dict[str, Any], coverage: str) -> str:
    item_name = str(item.get("item_name", "")).strip()
    desc = str(item.get("description", "")).strip()
    if coverage == "PARTIALLY_COVERED":
        return f"'{item_name}' ê´€ë ¨ ë‚´ìš©ì€ ë³´ì´ì§€ë§Œ ê·¼ê±°ê°€ ì•½í•©ë‹ˆë‹¤. {desc}ë¥¼ ìˆ˜ì¹˜/ì‚¬ë¡€ì™€ í•¨ê»˜ ë³´ê°•í•˜ì„¸ìš”."
    return f"'{item_name}' í•­ëª©ì„ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”. {desc}"


def _validate_and_repair_criteria(criteria_scores: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    # SEB_01/SEB_02 style guardrail: score>0 must have related slides.
    for c in criteria_scores:
        score = int(c.get("score", 0))
        related = c.get("related_slides", []) or []
        if score > 0 and not related:
            c["score"] = 0
            c["raw_score"] = 0.0
            c["coverage_status"] = "NOT_COVERED"
            c["is_covered"] = False
            c["feedback"] = "ê·¼ê±° ìŠ¬ë¼ì´ë“œê°€ í™•ì¸ë˜ì§€ ì•Šì•„ ì ìˆ˜ë¥¼ 0ì ìœ¼ë¡œ ë³´ì •í–ˆìŠµë‹ˆë‹¤."
            if not c.get("missing_items"):
                c["missing_items"] = [
                    {
                        "item_id": f"{c.get('criteria_id', 'unknown')}_MISSING",
                        "item_name": c.get("criteria_name", "ê¸°ì¤€"),
                        "suggestion": "í•´ë‹¹ ê¸°ì¤€ì„ ë‹¤ë£¨ëŠ” ê·¼ê±° ìŠ¬ë¼ì´ë“œë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì¶”ê°€í•˜ì„¸ìš”.",
                    }
                ]
    return criteria_scores


def _retrieve_top_k(
    item: Dict[str, Any],
    slides: List[Dict[str, Any]],
    top_k: int,
    group_id: str = "",
) -> List[Dict[str, Any]]:
    item_vec = item.get("embedding", [])
    item_text = f"{item.get('item_name', '')} {item.get('description', '')}".strip()
    prior_categories = GROUP_CATEGORY_PRIORS.get(group_id, set())
    scored = []
    min_retrieval_sim = float(os.getenv("IR_RETR_MIN_SIM", "0.02"))
    for slide in slides:
        if slide.get("text_deficiency_flag"):
            continue
        vec_sim = _cosine(item_vec, slide.get("embedding", []))
        slide_text = f"{slide.get('clean_text', '')} {slide.get('short_summary', '')}"
        lex_sim = _lexical_similarity(item_text, slide_text)
        ngram_sim = _ngram_similarity(item_text, slide_text)
        kw_sim = _keyword_overlap_score(item_text, slide_text)
        blend_sim = (0.40 * vec_sim) + (0.25 * lex_sim) + (0.20 * ngram_sim) + (0.15 * kw_sim)
        robust_sim = max(lex_sim, ngram_sim, (0.85 * vec_sim) + (0.15 * kw_sim))
        sim = max(blend_sim, robust_sim)
        if prior_categories and slide.get("category") in prior_categories:
            sim = min(1.0, sim + 0.12)
            if float(slide.get("category_confidence", 0.0)) >= 0.7:
                sim = min(1.0, sim + 0.04)
        if _item_prefers_numeric(item_text):
            digit_cnt = len(re.findall(r"\d", slide_text))
            if digit_cnt >= 6:
                sim = min(1.0, sim + 0.06)
            elif digit_cnt >= 3:
                sim = min(1.0, sim + 0.03)
        if sim < min_retrieval_sim:
            continue
        scored.append(
            {
                "slide_number": slide["slide_number"],
                "similarity": sim,
                "summary": slide["short_summary"],
                "clean_text": slide["clean_text"][:1000],
            }
        )
    scored.sort(key=lambda x: x["similarity"], reverse=True)
    return scored[:top_k]


def _keyword_overlap_score(item_text: str, slide_text: str) -> float:
    item_tokens = set(re.findall(r"[a-zA-Z0-9ê°€-í£_]+", (item_text or "").lower()))
    slide_tokens = set(re.findall(r"[a-zA-Z0-9ê°€-í£_]+", (slide_text or "").lower()))
    if not item_tokens or not slide_tokens:
        return 0.0
    overlap = len(item_tokens & slide_tokens)
    denom = max(1, min(len(item_tokens), 10))
    return max(0.0, min(1.0, overlap / denom))


def _item_prefers_numeric(item_text: str) -> bool:
    t = (item_text or "").lower()
    numeric_hints = [
        "tam",
        "sam",
        "som",
        "ì‹œì¥",
        "ë§¤ì¶œ",
        "ìˆ˜ìµ",
        "ê°€ê²©",
        "arpu",
        "ltv",
        "mau",
        "dau",
        "bep",
        "ì¬ë¬´",
        "ì„±ì¥",
        "ì¶”ì„¸",
    ]
    return any(k in t for k in numeric_hints)


def _lexical_similarity(a: str, b: str) -> float:
    ta = set(re.findall(r"[a-zA-Z0-9ê°€-í£_]+", (a or "").lower()))
    tb = set(re.findall(r"[a-zA-Z0-9ê°€-í£_]+", (b or "").lower()))
    if not ta or not tb:
        return 0.0
    inter = len(ta & tb)
    union = len(ta | tb)
    if union == 0:
        return 0.0
    return inter / union


def _ngram_similarity(a: str, b: str, n: int = 3) -> float:
    aa = re.sub(r"\s+", "", (a or "").lower())
    bb = re.sub(r"\s+", "", (b or "").lower())
    if len(aa) < n or len(bb) < n:
        return 0.0
    ga = {aa[i : i + n] for i in range(len(aa) - n + 1)}
    gb = {bb[i : i + n] for i in range(len(bb) - n + 1)}
    if not ga or not gb:
        return 0.0
    inter = len(ga & gb)
    union = len(ga | gb)
    return inter / union if union else 0.0


def _cosine(a: List[float], b: List[float]) -> float:
    if not a or not b:
        return 0.0
    n = min(len(a), len(b))
    dot = sum(a[i] * b[i] for i in range(n))
    na = sqrt(sum(a[i] * a[i] for i in range(n)))
    nb = sqrt(sum(b[i] * b[i] for i in range(n)))
    if na == 0 or nb == 0:
        return 0.0
    return max(0.0, min(1.0, dot / (na * nb)))


def _decide_coverage(item: Dict[str, Any], evidences: List[Dict[str, Any]], gemini: GeminiJSONClient) -> str:
    max_sim = evidences[0]["similarity"] if evidences else 0.0
    fail_if_missing = bool(item.get("fail_if_missing", False))
    sim_high = _sim_high()
    sim_mid = _sim_mid()
    sim_low = _sim_low()

    # Local/offline fallback: keep partial coverage signal when semantic model is unavailable.
    if not gemini.model and sim_low <= max_sim < sim_mid:
        return "PARTIALLY_COVERED"

    if max_sim >= sim_high:
        if evidences and len((evidences[0].get("clean_text") or "").strip()) < 20:
            return _llm_review(item, evidences[:2], gemini)
        return "COVERED"

    if sim_mid <= max_sim < sim_high:
        reviewed = _llm_review(item, evidences[:2], gemini)
        return "PARTIALLY_COVERED" if reviewed == "NOT_COVERED" else reviewed

    if sim_low <= max_sim < sim_mid and evidences:
        if fail_if_missing:
            reviewed = _llm_review(item, evidences[:2], gemini)
            return "PARTIALLY_COVERED" if reviewed == "NOT_COVERED" else reviewed
        return "PARTIALLY_COVERED"

    if fail_if_missing:
        return _llm_review(item, evidences[:2], gemini)
    return "NOT_COVERED"


def _llm_review(item: Dict[str, Any], evidences: List[Dict[str, Any]], gemini: GeminiJSONClient) -> str:
    if os.getenv("IR_FAST_MODE") == "1":
        top = evidences[0]["similarity"] if evidences else 0.0
        if top >= _sim_high():
            return "COVERED"
        if top >= _sim_mid():
            return "PARTIALLY_COVERED"
        if top >= _sim_low():
            return "PARTIALLY_COVERED"
        return "NOT_COVERED"

    if not gemini.model or not evidences:
        top = evidences[0]["similarity"] if evidences else 0.0
        if top >= _sim_high():
            return "COVERED"
        if top >= _sim_mid():
            return "PARTIALLY_COVERED"
        if top >= _sim_low():
            return "PARTIALLY_COVERED"
        return "NOT_COVERED"
    try:
        prompt = {
            "item_name": item.get("item_name"),
            "item_description": item.get("description"),
            "evidence_slides": [
                {"slide_number": e["slide_number"], "summary": e["summary"], "similarity": e["similarity"]} for e in evidences
            ],
            "question": "ì¦ê±° ìŠ¬ë¼ì´ë“œê°€ í•­ëª©ì„ ì¶©ì¡±í•˜ëŠ”ê°€? JSONë§Œ ë°˜í™˜",
            "output_format": {"is_relevant": True, "confidence": 0.0},
        }
        out = gemini.generate_json(json.dumps(prompt, ensure_ascii=False), temperature=0.0)
        is_rel = bool(out.get("is_relevant", False))
        conf = _clamp01(float(out.get("confidence", 0.0)))
        if is_rel and conf >= 0.6:
            return "COVERED"
        if is_rel:
            return "PARTIALLY_COVERED"
        return "NOT_COVERED"
    except Exception:
        top = evidences[0]["similarity"] if evidences else 0.0
        if top >= _sim_high():
            return "COVERED"
        if top >= _sim_mid():
            return "PARTIALLY_COVERED"
        if top >= _sim_low():
            return "PARTIALLY_COVERED"
        return "NOT_COVERED"


def _score_item(item_max: float, coverage: str, similarity: float) -> float:
    if coverage == "NOT_COVERED":
        return 0.0
    if coverage == "PARTIALLY_COVERED":
        sim_high = max(0.01, min(0.99, _sim_high()))
        ratio = max(0.35, min(0.70, (similarity / sim_high) * 0.70))
        return round(item_max * ratio, 2)
    # COVERED
    sim_high = max(0.01, min(0.99, _sim_high()))
    ratio = 0.65 + max(0.0, min(1.0, (similarity - sim_high) / (1.0 - sim_high))) * 0.35
    return round(item_max * ratio, 2)


def _reduce_group_coverage(values: List[str], weights: Optional[List[float]] = None) -> str:
    if not values:
        return "NOT_COVERED"
    score_map = {"COVERED": 1.0, "PARTIALLY_COVERED": 0.5, "NOT_COVERED": 0.0}
    if not weights or len(weights) != len(values):
        weighted = sum(score_map.get(v, 0.0) for v in values) / max(1, len(values))
    else:
        denom = sum(max(0.0, w) for w in weights) or 1.0
        weighted = sum(score_map.get(v, 0.0) * max(0.0, w) for v, w in zip(values, weights)) / denom
    if weighted >= 0.60:
        return "COVERED"
    if weighted >= 0.25:
        return "PARTIALLY_COVERED"
    return "NOT_COVERED"


def _group_interpretation(group: Dict[str, Any]) -> str:
    item_names = [str(i.get("item_name", "")).strip() for i in group.get("items", []) if i.get("item_name")]
    return f"{group.get('group_name', '')} í‰ê°€ëŠ” ë‹¤ìŒ í•­ëª©ì„ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨í•©ë‹ˆë‹¤: {', '.join(item_names)}"


def _build_group_feedback(
    group: Dict[str, Any],
    evidence_for_group: List[Dict[str, Any]],
    missing_items: List[Dict[str, str]],
    gemini: GeminiJSONClient,
) -> Tuple[str, float]:
    if os.getenv("IR_FAST_MODE") == "1":
        if missing_items:
            return (
                f"{group.get('group_name')} í•­ëª©ì—ì„œ ëˆ„ë½ ìš”ì†Œê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. "
                f"ëˆ„ë½: {', '.join(m['item_name'] for m in missing_items[:2])}",
                0.68,
            )
        return f"{group.get('group_name')} í•­ëª©ì€ ì£¼ìš” ê·¼ê±°ê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.", 0.74

    if gemini.model:
        try:
            prompt = {
                "group_name": group.get("group_name"),
                "group_items": [i.get("item_name") for i in group.get("items", [])],
                "evidence": evidence_for_group,
                "missing_items": missing_items,
                "instruction": "ê·¼ê±° ê¸°ë°˜ìœ¼ë¡œ 2ë¬¸ì¥ í”¼ë“œë°± ì‘ì„±. ê³¼ì¥ ê¸ˆì§€. JSONë§Œ ë°˜í™˜.",
                "output_format": {"feedback": "...", "confidence": 0.0},
            }
            out = gemini.generate_json(json.dumps(prompt, ensure_ascii=False), temperature=0.2)
            feedback = str(out.get("feedback", "")).strip()
            confidence = _clamp01(float(out.get("confidence", 0.75)))
            if feedback:
                return feedback, confidence
        except Exception:
            pass

    if missing_items:
        top_ev = [ev for ev in evidence_for_group if ev.get("top_summary")]
        ev_hint = f" ê·¼ê±° ì˜ˆì‹œ: {top_ev[0]['top_summary'][:70]}..." if top_ev else ""
        return (
            f"{group.get('group_name')} í•­ëª©ì—ì„œ ì¼ë¶€ í•„ìˆ˜ ê·¼ê±°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. "
            f"ëˆ„ë½: {', '.join(m['item_name'] for m in missing_items[:2])}.{ev_hint}",
            0.65,
        )
    top_ev = [ev for ev in evidence_for_group if ev.get("top_summary")]
    ev_hint = f" ì£¼ìš” ê·¼ê±°: {top_ev[0]['top_summary'][:80]}..." if top_ev else ""
    return f"{group.get('group_name')} í•­ëª©ì€ ê·¼ê±° ìŠ¬ë¼ì´ë“œê°€ í™•ì¸ë˜ì–´ ë¹„êµì  ì•ˆì •ì ìœ¼ë¡œ ì»¤ë²„ë˜ì—ˆìŠµë‹ˆë‹¤.{ev_hint}", 0.72


def _build_deck_score(
    criteria_scores: List[Dict[str, Any]],
    rubric: Dict[str, Any],
    strategy: Optional[Dict[str, Any]],
    gemini: GeminiJSONClient,
) -> Dict[str, Any]:
    group_by_id = {g.get("group_id"): g for g in rubric.get("groups", [])}
    weighted_sum = 0.0
    for c in criteria_scores:
        gid = c.get("criteria_id")
        weight = float(group_by_id.get(gid, {}).get("group_weight", 0.0))
        weighted_sum += (float(c.get("raw_score", 0.0)) / max(float(c.get("raw_max_score", 1.0)), 1.0)) * weight
    total_score = int(round(weighted_sum * 100))

    sorted_low = sorted(criteria_scores, key=lambda x: x.get("score", 0))
    improvements = [f"{c['criteria_name']} ë³´ê°•: {c['feedback']}" for c in sorted_low[:3]]
    strengths = [f"{c['criteria_name']} ê°•ì : {c['feedback']}" for c in sorted(criteria_scores, key=lambda x: x.get("score", 0), reverse=True)[:3]]
    top_actions = []
    for c in sorted_low[:3]:
        missing = c.get("missing_items", [])
        if missing:
            top_actions.append(f"{c['criteria_name']}: {missing[0].get('suggestion', '')}")
        else:
            top_actions.append(f"{c['criteria_name']}: í•µì‹¬ ê·¼ê±° ìŠ¬ë¼ì´ë“œ ìˆ˜ì¹˜ë¥¼ ê°•í™”í•˜ì„¸ìš”.")

    structure_summary = _build_structure_summary(criteria_scores, strategy, gemini)
    return {
        "total_score": max(0, min(100, total_score)),
        "structure_summary": structure_summary,
        "strengths": strengths,
        "improvements": improvements,
        "top_actions": top_actions,
    }


def _build_structure_summary(
    criteria_scores: List[Dict[str, Any]],
    strategy: Optional[Dict[str, Any]],
    gemini: GeminiJSONClient,
) -> str:
    if gemini.model:
        try:
            payload = {
                "strategy": strategy or {},
                "criteria_scores": [
                    {"name": c["criteria_name"], "score": c["score"], "feedback": c["feedback"]} for c in criteria_scores
                ],
                "instruction": "IR ë± êµ¬ì¡° ì´í‰ì„ 3~4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±. JSONë§Œ ë°˜í™˜.",
                "output_format": {"summary": "..."},
            }
            out = gemini.generate_json(json.dumps(payload, ensure_ascii=False), temperature=0.2)
            summary = str(out.get("summary", "")).strip()
            if summary:
                return summary
        except Exception:
            pass
    return "ë¬¸ì œ-í•´ê²°-ì‹œì¥-ì‹¤í–‰ê³„íšì˜ ê¸°ë³¸ íë¦„ì€ ìœ ì§€ë˜ì—ˆì§€ë§Œ, ë‚®ì€ ì ìˆ˜ í•­ëª©ì˜ ê·¼ê±°ë¥¼ ë³´ê°•í•˜ë©´ ì„¤ë“ë ¥ì´ ê°œì„ ë©ë‹ˆë‹¤."


def _build_presentation_guide(
    slides: List[Dict[str, Any]],
    criteria_scores: List[Dict[str, Any]],
    strategy: Optional[Dict[str, Any]],
) -> Dict[str, Any]:
    low_criteria = sorted(criteria_scores, key=lambda x: x.get("score", 0))[:2]
    emphasized = []
    seen = set()
    for c in low_criteria:
        for sn in c.get("related_slides", [])[:2]:
            if sn in seen:
                continue
            seen.add(sn)
            emphasized.append(
                {
                    "slide_number": sn,
                    "reason": f"{c.get('criteria_name')} ë³´ì™„ì„ ìœ„í•´ í•´ë‹¹ ìŠ¬ë¼ì´ë“œì˜ í•µì‹¬ ìˆ˜ì¹˜/ê·¼ê±°ë¥¼ ë¨¼ì € ê°•ì¡°í•˜ì„¸ìš”.",
                }
            )
    if not emphasized and slides:
        emphasized = [{"slide_number": 1, "reason": "ì˜¤í”„ë‹ ë©”ì‹œì§€ë¥¼ ëª…í™•íˆ ì œì‹œí•˜ì„¸ìš”."}]

    pitch_hint = str((strategy or {}).get("type", "VC_DEMO"))
    return {
        "emphasized_slides": emphasized,
        "guide": [
            "ì˜¤í”„ë‹ì—ì„œ ë¬¸ì œì˜ í¬ê¸°ì™€ ëŒ€ìƒ ê³ ê°ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ë¨¼ì € ì œì‹œí•˜ì„¸ìš”.",
            "ì¤‘ê°„ì—ëŠ” ìˆ˜ì¹˜ ê·¼ê±°ê°€ ìˆëŠ” ìŠ¬ë¼ì´ë“œë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª… ìˆœì„œë¥¼ ìœ ì§€í•˜ì„¸ìš”.",
            "í´ë¡œì§•ì—ì„œëŠ” ì‹¤í–‰ ê³„íšê³¼ ìš”ì²­ì‚¬í•­(íˆ¬ì/ì„ ì •/ì§€ì› í•„ìš”ì„±)ì„ ëª…í™•íˆ ì •ë¦¬í•˜ì„¸ìš”.",
            f"í˜„ì¬ í”¼ì¹­ ë§¥ë½({pitch_hint})ì— ë§ì¶° ì‹¬ì‚¬ í¬ì¸íŠ¸ë¥¼ ë°˜ë³µ ê°•ì¡°í•˜ì„¸ìš”.",
        ],
        "time_allocation": [
            {"section": "ì˜¤í”„ë‹", "seconds": 60},
            {"section": "ë³¸ë¡ ", "seconds": 360},
            {"section": "í´ë¡œì§•", "seconds": 60},
        ],
    }


def _build_slide_cards(slides: List[Dict[str, Any]], criteria_scores: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    score_by_slide: Dict[int, List[int]] = {}
    criteria_by_slide: Dict[int, List[str]] = {}
    for c in criteria_scores:
        for sn in c.get("related_slides", []):
            score_by_slide.setdefault(sn, []).append(int(c.get("score", 0)))
            criteria_by_slide.setdefault(sn, []).append(str(c.get("criteria_name", "")))

    out = []
    for slide in slides:
        sn = slide["slide_number"]
        linked_scores = score_by_slide.get(sn, [])
        text_len = len(slide.get("clean_text", ""))
        numbers = len(re.findall(r"\d", slide.get("clean_text", "")))
        cat_conf = float(slide.get("category_confidence", 0.5))

        base = 45
        if linked_scores:
            base += int(round(sum(linked_scores) / len(linked_scores) * 0.35))
        base += int(round(cat_conf * 20))
        if numbers >= 8:
            base += 8
        elif numbers >= 3:
            base += 4
        if slide.get("category") == "OTHER":
            base -= 8
        if text_len > 1200:
            base -= 6
        if text_len < 40:
            base -= 10
        if slide["text_deficiency_flag"]:
            base = min(base, 50)
        detail = _slide_feedback(
            slide=slide,
            score=max(0, min(100, base)),
            matched_criteria=sorted(set(criteria_by_slide.get(sn, []))),
            numeric_count=numbers,
        )
        out.append(
            {
                "slide_id": f"slide-{sn}",
                "slide_number": sn,
                "category": slide["category"],
                "score": max(0, min(100, base)),
                "thumbnail_url": None,
                "content": slide["short_summary"],
                "display_order": sn,
                "feedback": detail,
            }
        )
    return out


def _slide_feedback(
    slide: Dict[str, Any],
    score: int,
    matched_criteria: List[str],
    numeric_count: int,
) -> Dict[str, Any]:
    strengths = []
    improvements = []
    if slide["category"] != "OTHER":
        strengths.append(f"{slide['category']} ëª©ì ì˜ ë©”ì‹œì§€ê°€ í™•ì¸ë©ë‹ˆë‹¤.")
    if len(slide.get("key_claims", [])) >= 2:
        strengths.append("í•µì‹¬ ì£¼ì¥ ë¬¸ì¥ì´ 2ê°œ ì´ìƒ ìˆì–´ ì „ë‹¬ í¬ì¸íŠ¸ê°€ ë¶„ëª…í•©ë‹ˆë‹¤.")
    if numeric_count >= 3:
        strengths.append("ìˆ˜ì¹˜ ì •ë³´ê°€ í¬í•¨ë˜ì–´ ê°ê´€ì  ì„¤ëª…ì— ìœ ë¦¬í•©ë‹ˆë‹¤.")
    if matched_criteria:
        strengths.append(f"ê´€ë ¨ ê¸°ì¤€: {', '.join(matched_criteria[:2])}")

    if slide.get("text_deficiency_flag"):
        improvements.append("í…ìŠ¤íŠ¸ ê·¼ê±°ê°€ ë¶€ì¡±í•˜ë¯€ë¡œ í•µì‹¬ ë¬¸ì¥/ìˆ˜ì¹˜ë¥¼ 1~2ê°œ ì¶”ê°€í•˜ì„¸ìš”.")
    if len(slide.get("clean_text", "")) > 900:
        improvements.append("í…ìŠ¤íŠ¸ ë°€ë„ê°€ ë†’ì•„ í•µì‹¬ ë¬¸ì¥ ì¤‘ì‹¬ìœ¼ë¡œ ì••ì¶•í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤.")
    if numeric_count == 0:
        improvements.append("ì •ëŸ‰ ê·¼ê±°(ì‹œì¥/ì‚¬ìš©ì/ë§¤ì¶œ ë“±) ìˆ˜ì¹˜ë¥¼ ìµœì†Œ 1ê°œ ì´ìƒ ë„£ì–´ì£¼ì„¸ìš”.")
    if slide.get("category") in {"MARKET", "BUSINESS_MODEL"} and numeric_count < 2:
        improvements.append("ì‹œì¥/ìˆ˜ìµ ìŠ¬ë¼ì´ë“œëŠ” ê³„ì‚°ì‹ ë˜ëŠ” ê¸°ì¤€ë…„/ì¶œì²˜ë¥¼ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”.")
    if slide.get("category") == "TEAM":
        improvements.append("íŒ€ ìŠ¬ë¼ì´ë“œëŠ” ì—­í• /ê²½ë ¥/ì‹¤í–‰ì„±ê³¼ë¥¼ í•œ ì¤„ì”© ë¶„ë¦¬í•´ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.")
    if not improvements:
        improvements.append("í•µì‹¬ ì£¼ì¥ 1ê°œë¥¼ ì œëª©ìœ¼ë¡œ ëŒì–´ì˜¬ë¦¬ê³ , ë³¸ë¬¸ì€ ê·¼ê±° 2ê°œë¡œ ì••ì¶•í•˜ì„¸ìš”.")

    preview = (slide.get("short_summary", "") or "").strip()
    preview = preview[:90] + ("..." if len(preview) > 90 else "")
    detailed = (
        f"ìŠ¬ë¼ì´ë“œ {slide['slide_number']}({slide['category']}) ì ìˆ˜ëŠ” {score}ì ì…ë‹ˆë‹¤. "
        f"ìš”ì•½: {preview}"
    )
    return {
        "detailed_feedback": detailed,
        "strengths": strengths[:3],
        "improvements": improvements[:3],
    }


def _clamp01(value: float) -> float:
    return max(0.0, min(1.0, value))
