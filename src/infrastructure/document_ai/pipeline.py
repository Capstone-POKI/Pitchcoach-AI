from pathlib import Path
from typing import Dict
import logging

from src.utils.io_utils import read_json
from src.infrastructure.document_ai.processor import (
    merge_chunk_results,
    process_document,
    process_pdf_ocr_in_chunks,
)


logger = logging.getLogger("POKI")


def _is_page_limit_error(exc: Exception) -> bool:
    msg = str(exc).lower()
    return "page_limit_exceeded" in msg or "document pages" in msg or "page limit" in msg


def _get_pdf_page_count(pdf_path: Path) -> int | None:
    try:
        from PyPDF2 import PdfReader
    except Exception:
        return None

    try:
        reader = PdfReader(str(pdf_path))
        return len(reader.pages)
    except Exception:
        return None


def run_document_ai_pipeline(
    pdf_path: Path,
    output_dir: Path,
    use_chunking: bool = False,
    pages_per_chunk: int = 15,
) -> Dict:
    print(f"\nğŸ“„ [OCR] {pdf_path.name}")
    output_path = output_dir / f"{pdf_path.stem}_docai.json"

    if output_path.exists():
        print(f"âš¡ï¸ ê¸°ì¡´ ê²°ê³¼ ì¬ì‚¬ìš©: {output_path.name}")
        return read_json(str(output_path))

    # Proactive switch: if page count exceeds non-chunking practical limit, force chunking first.
    page_count = _get_pdf_page_count(pdf_path)
    if page_count is not None and page_count > pages_per_chunk and not use_chunking:
        print(f"   âš™ï¸ í˜ì´ì§€ ìˆ˜ {page_count}p ê°ì§€ -> chunking ìë™ ì „í™˜ ({pages_per_chunk}p ë‹¨ìœ„)")
        use_chunking = True

    try:
        if use_chunking:
            print("   âš™ï¸ ëŒ€ìš©ëŸ‰ ë¶„í•  ì²˜ë¦¬ ì¤‘...")
            chunk_dir = output_dir / f"{pdf_path.stem}_chunks"
            chunk_results = process_pdf_ocr_in_chunks(
                str(pdf_path),
                str(chunk_dir),
                pages_per_chunk=pages_per_chunk,
            )
            return merge_chunk_results(chunk_results, str(output_path))
        return process_document(str(pdf_path), "OCR", str(output_path))
    except Exception as e:
        # Root fix: fallback to chunking automatically when page limit is exceeded.
        if not use_chunking and _is_page_limit_error(e):
            logger.warning(f"âš ï¸ OCR í˜ì´ì§€ ì œí•œ ê°ì§€, chunking ëª¨ë“œë¡œ ìë™ ì „í™˜: {e}")
            try:
                chunk_dir = output_dir / f"{pdf_path.stem}_chunks"
                chunk_results = process_pdf_ocr_in_chunks(
                    str(pdf_path),
                    str(chunk_dir),
                    pages_per_chunk=pages_per_chunk,
                )
                return merge_chunk_results(chunk_results, str(output_path))
            except Exception as chunk_err:
                logger.error(f"âŒ OCR chunking ì¬ì‹œë„ ì‹¤íŒ¨: {chunk_err}")
                return {}

        logger.error(f"âŒ OCR ì‹¤íŒ¨: {e}")
        return {}
