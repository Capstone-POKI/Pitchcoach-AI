print("--- [ì‹œìŠ¤í…œ] ì´ˆê¸°í™” ì‹œì‘ ---")

import os
import sys
import logging
from pathlib import Path
from typing import Dict, Optional
from dotenv import load_dotenv

# ----------------------------------------------------------------
# [Mac í•„ìˆ˜ ì„¤ì •] ì´ê²ƒë§Œ ìˆìœ¼ë©´ ë©ë‹ˆë‹¤ (ë²„ì „ ë§ì¶”ë©´ í•´ê²°ë¨)
# ----------------------------------------------------------------
os.environ["GRPC_DNS_RESOLVER"] = "native"
os.environ["GRPC_POLL_STRATEGY"] = "poll"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# 1. í™˜ê²½ ì„¤ì •
load_dotenv()
logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger("POKI")

# 2. ê²½ë¡œ ì„¤ì •
if "__file__" in locals():
    PROJECT_ROOT = Path(__file__).resolve().parents[2]
else:
    PROJECT_ROOT = Path.cwd()

INPUT_DIR = PROJECT_ROOT / "data" / "input"
OUTPUT_DIR = PROJECT_ROOT / "data" / "output"

# 3. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ (ì´ì œ ë©ˆì¶”ì§€ ì•Šì„ ê²ƒì…ë‹ˆë‹¤)
print("âš™ï¸ [ì‹œìŠ¤í…œ] AI ì—”ì§„ ë¡œë”© ì¤‘...")
try:
    import torch
    from transformers import LayoutLMv3Processor
    from src.docs_analysis.layoutlm.preprocess import prepare_layoutlm_input, load_docai_json
    from src.docs_analysis.document_ai.processor import process_document, process_pdf_ocr_in_chunks, merge_chunk_results
    from src.utils.io_utils import save_json, read_json
except ImportError as e:
    print(f"âŒ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {e}")
    sys.exit(1)


def run_document_ai_pipeline(pdf_path: Path, use_chunking: bool = False) -> Dict:
    print(f"\nğŸ“„ [Step 1] Document AI (OCR): {pdf_path.name}")
    output_path = OUTPUT_DIR / f"{pdf_path.stem}_docai.json"
    
    if output_path.exists():
        print(f"âš¡ï¸ ê¸°ì¡´ ê²°ê³¼ ì¬ì‚¬ìš©: {output_path.name}")
        return read_json(str(output_path))
    
    try:
        if use_chunking:
            print("   âš™ï¸ ëŒ€ìš©ëŸ‰ ë¶„í•  ì²˜ë¦¬ ì¤‘...")
            chunk_dir = OUTPUT_DIR / f"{pdf_path.stem}_chunks"
            chunk_results = process_pdf_ocr_in_chunks(str(pdf_path), str(chunk_dir), pages_per_chunk=15)
            return merge_chunk_results(chunk_results, str(output_path))
        return process_document(str(pdf_path), "OCR", str(output_path))
    except Exception as e:
        logger.error(f"âŒ OCR ì‹¤íŒ¨: {e}")
        return {}

def run_layoutlm_pipeline(pdf_path: Path, docai_json_path: Path) -> Dict:
    print(f"\nğŸ¤– [Step 2] LayoutLM êµ¬ì¡° ë¶„ì„")
    try:
        docai_result = load_docai_json(str(docai_json_path))
        processor = LayoutLMv3Processor.from_pretrained("microsoft/layoutlmv3-base", apply_ocr=False)
        layoutlm_input = prepare_layoutlm_input(docai_result, str(pdf_path), processor)
        
        result = {
            "doc_type": "ir_deck",
            "status": "success",
            "input_shape": str(layoutlm_input["input_ids"].shape)
        }
        
        save_path = OUTPUT_DIR / f"{pdf_path.stem}_layoutlm.json"
        save_json(result, str(save_path))
        print(f"   âœ… ë¶„ì„ ì™„ë£Œ: {save_path.name}")
        return result
    except Exception as e:
        logger.error(f"âŒ LayoutLM ì‹¤íŒ¨: {e}")
        return {}

def main():
    INPUT_DIR.mkdir(parents=True, exist_ok=True)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    
    print("\nğŸš€ POKI-AI íŒŒì´í”„ë¼ì¸ ì‹œì‘")
    
    # Gemini ì´ˆê¸°í™”
    gemini = None
    try:
        from src.docs_analysis.llm.gemini_client import GeminiAnalyst
        from src.docs_analysis.post_processing.exporter import export_final_json
        gemini = GeminiAnalyst()
        print("â˜ï¸ Gemini ì—°ê²° ì„±ê³µ!")
    except:
        print("âš ï¸ Gemini ì—°ê²° ì‹¤íŒ¨ (ê¸°ë³¸ ë¶„ì„ë§Œ ì§„í–‰)")

    # [Phase 1] ê³µê³ ë¬¸
    notice_pdf = INPUT_DIR / "sample_notice.pdf"
    strategy = {"type": "general", "focus_point": "ê¸°ë³¸"}
    if notice_pdf.exists():
        res = run_document_ai_pipeline(notice_pdf)
        if gemini and res.get("text"):
            strategy = gemini.analyze_notice(res.get("text", ""))
            print(f"ğŸ¯ ì „ëµ: {strategy.get('focus_point')}")

    # [Phase 2] IR Deck
    ir_pdf = INPUT_DIR / "sample_irdeck.pdf"
    if ir_pdf.exists():
        ocr_res = run_document_ai_pipeline(ir_pdf, use_chunking=True)
        lm_res = run_layoutlm_pipeline(ir_pdf, OUTPUT_DIR / f"{ir_pdf.stem}_docai.json")
        
        final_path = OUTPUT_DIR / f"{ir_pdf.stem}_final.json"
        if gemini:
            export_final_json(ocr_res, lm_res, str(final_path), strategy)
        print(f"\nâœ¨ ì „ì²´ ì™„ë£Œ! ê²°ê³¼: {final_path}")
    else:
        print(f"âŒ íŒŒì¼ ì—†ìŒ: {ir_pdf}")

if __name__ == "__main__":
    main()