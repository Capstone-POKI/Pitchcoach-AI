# src/layoutlm/preprocess.py
"""
LayoutLM ì „ì²˜ë¦¬ ë° ë¼ë²¨ ì •ì˜
"""

from typing import Dict, List, Tuple
from pdf2image import convert_from_path
from src.utils.io_utils import read_json


# ê³µê³ ë¬¸ ë¼ë²¨ (17ê°œ)
ANNOUNCEMENT_LABELS = [
    "O",
    "B-ê³µê³ ì œëª©", "I-ê³µê³ ì œëª©",
    "B-ê³µê³ ë²ˆí˜¸", "I-ê³µê³ ë²ˆí˜¸",
    "B-ì˜ˆì‚°ê¸ˆì•¡", "I-ì˜ˆì‚°ê¸ˆì•¡",
    "B-ë°œì£¼ê¸°ê´€", "I-ë°œì£¼ê¸°ê´€",
    "B-ì‚¬ì—…ë‚´ìš©", "I-ì‚¬ì—…ë‚´ìš©",
    "B-ê³„ì•½ê¸°ê°„", "I-ê³„ì•½ê¸°ê°„",
    "B-ì œì¶œë§ˆê°", "I-ì œì¶œë§ˆê°",
]

# Pitch Deck ë¼ë²¨ (85ê°œ)
PITCH_DECK_LABELS = [
    "O",
    # íšŒì‚¬ ê¸°ë³¸ ì •ë³´
    "B-íšŒì‚¬ëª…", "I-íšŒì‚¬ëª…",
    "B-ìŠ¬ë¡œê±´", "I-ìŠ¬ë¡œê±´",
    "B-ëŒ€í‘œì", "I-ëŒ€í‘œì",
    "B-ì—°ë½ì²˜", "I-ì—°ë½ì²˜",
    
    # ì œí’ˆ/ì„œë¹„ìŠ¤
    "B-ì œí’ˆëª…", "I-ì œí’ˆëª…",
    "B-ì œí’ˆì„¤ëª…", "I-ì œí’ˆì„¤ëª…",
    "B-í•µì‹¬ê¸°ëŠ¥", "I-í•µì‹¬ê¸°ëŠ¥",
    "B-íŠ¹ì¥ì ", "I-íŠ¹ì¥ì ",
    "B-ê°€ê²©", "I-ê°€ê²©",
    
    # ì‹œì¥ ì •ë³´
    "B-ì‹œì¥ê·œëª¨", "I-ì‹œì¥ê·œëª¨",
    "B-ì„±ì¥ë¥ ", "I-ì„±ì¥ë¥ ",
    "B-íƒ€ê²Ÿì‹œì¥", "I-íƒ€ê²Ÿì‹œì¥",
    "B-ì‹œì¥íŠ¸ë Œë“œ", "I-ì‹œì¥íŠ¸ë Œë“œ",
    "B-ê·œì œì •ë³´", "I-ê·œì œì •ë³´",
    
    # ì¬ë¬´ ì •ë³´
    "B-ë§¤ì¶œì•¡", "I-ë§¤ì¶œì•¡",
    "B-íˆ¬ìê¸ˆì•¡", "I-íˆ¬ìê¸ˆì•¡",
    "B-ë¹„ìš©", "I-ë¹„ìš©",
    "B-ê°€ê²©ì •ì±…", "I-ê°€ê²©ì •ì±…",
    
    # ê¸°ìˆ  ì •ë³´
    "B-ê¸°ìˆ ëª…", "I-ê¸°ìˆ ëª…",
    "B-ê¸°ìˆ ì„¤ëª…", "I-ê¸°ìˆ ì„¤ëª…",
    "B-íŠ¹í—ˆ", "I-íŠ¹í—ˆ",
    "B-ê¸°ìˆ í‚¤ì›Œë“œ", "I-ê¸°ìˆ í‚¤ì›Œë“œ",
    
    # íŒ€ ì •ë³´
    "B-íŒ€ì›ëª…", "I-íŒ€ì›ëª…",
    "B-ì§ì±…", "I-ì§ì±…",
    "B-ê²½ë ¥", "I-ê²½ë ¥",
    
    # ê³ ê°/íŒŒíŠ¸ë„ˆ
    "B-ê³ ê°ì‚¬", "I-ê³ ê°ì‚¬",
    "B-íŒŒíŠ¸ë„ˆì‚¬", "I-íŒŒíŠ¸ë„ˆì‚¬",
    "B-ì œíœ´", "I-ì œíœ´",
    
    # ê²½ìŸì‚¬
    "B-ê²½ìŸì‚¬ëª…", "I-ê²½ìŸì‚¬ëª…",
    "B-ê²½ìŸìš°ìœ„", "I-ê²½ìŸìš°ìœ„",
    "B-ì°¨ë³„ì ", "I-ì°¨ë³„ì ",
    
    # ë¬¸ì œ/ì†”ë£¨ì…˜
    "B-ë¬¸ì œì ", "I-ë¬¸ì œì ",
    "B-ì†”ë£¨ì…˜", "I-ì†”ë£¨ì…˜",
    "B-ë°°ê²½", "I-ë°°ê²½",
    "B-ë¹„ì „", "I-ë¹„ì „",
    
    # ë§ˆì¼ìŠ¤í†¤
    "B-ë‚ ì§œ", "I-ë‚ ì§œ",
    "B-ê¸°ê°„", "I-ê¸°ê°„",
    "B-ë§ˆì¼ìŠ¤í†¤", "I-ë§ˆì¼ìŠ¤í†¤",
    "B-ì—°í˜", "I-ì—°í˜",
    
    # í†µê³„/ê¸°íƒ€
    "B-í†µê³„ìˆ˜ì¹˜", "I-í†µê³„ìˆ˜ì¹˜",
]

# IR Deck ë¼ë²¨ (47ê°œ)
IR_DECK_LABELS = [
    "O",
    # íšŒì‚¬ ì •ë³´
    "B-íšŒì‚¬ëª…", "I-íšŒì‚¬ëª…",
    "B-ì„¤ë¦½ì¼", "I-ì„¤ë¦½ì¼",
    "B-ëŒ€í‘œì", "I-ëŒ€í‘œì",
    
    # ì‚¬ì—… ì˜ì—­
    "B-ì‚¬ì—…ì˜ì—­", "I-ì‚¬ì—…ì˜ì—­",
    "B-ì œí’ˆëª…", "I-ì œí’ˆëª…",
    
    # ì¬ë¬´ ì •ë³´ (ìƒì„¸)
    "B-ë§¤ì¶œì•¡", "I-ë§¤ì¶œì•¡",
    "B-ì˜ì—…ì´ìµ", "I-ì˜ì—…ì´ìµ",
    "B-ìˆœì´ìµ", "I-ìˆœì´ìµ",
    "B-íˆ¬ìê¸ˆì•¡", "I-íˆ¬ìê¸ˆì•¡",
    "B-íˆ¬ìì", "I-íˆ¬ìì",
    
    # ì‹œì¥ ì •ë³´
    "B-ì‹œì¥ê·œëª¨", "I-ì‹œì¥ê·œëª¨",
    "B-TAM", "I-TAM",
    "B-SAM", "I-SAM",
    "B-SOM", "I-SOM",
    
    # ê¸°ìˆ  ì—­ëŸ‰
    "B-ê¸°ìˆ ì—­ëŸ‰", "I-ê¸°ìˆ ì—­ëŸ‰",
    "B-íŠ¹í—ˆ", "I-íŠ¹í—ˆ",
    "B-R&D", "I-R&D",
    
    # íŒ€ ì •ë³´
    "B-íŒ€ì›ëª…", "I-íŒ€ì›ëª…",
    "B-ì§ì±…", "I-ì§ì±…",
    "B-ê²½ë ¥", "I-ê²½ë ¥",
    "B-í•™ë ¥", "I-í•™ë ¥",
    
    # ê³ ê° ì •ë³´
    "B-ê³ ê°ì‚¬", "I-ê³ ê°ì‚¬",
    "B-ì‚¬ìš©ììˆ˜", "I-ì‚¬ìš©ììˆ˜",
    
    # í†µê³„
    "B-í†µê³„ìˆ˜ì¹˜", "I-í†µê³„ìˆ˜ì¹˜",
]


def get_labels(doc_type: str) -> List[str]:
    """ë¬¸ì„œ íƒ€ì…ì— ë§ëŠ” ë¼ë²¨ ë°˜í™˜"""
    
    doc_type = doc_type.lower()
    
    if doc_type in ["announcement", "notice"]:
        return ANNOUNCEMENT_LABELS
    elif doc_type in ["pitch_deck", "pitch"]:
        return PITCH_DECK_LABELS
    elif doc_type in ["ir_deck", "ir"]:
        return IR_DECK_LABELS
    else:
        print(f"âš ï¸ ì•Œ ìˆ˜ ì—†ëŠ” ë¬¸ì„œ íƒ€ì…: {doc_type}, ê¸°ë³¸ê°’(pitch_deck) ì‚¬ìš©")
        return PITCH_DECK_LABELS


def get_label_info(doc_type: str = None) -> Dict:
    """ë¼ë²¨ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜"""
    
    info = {
        "announcement": {
            "count": len(ANNOUNCEMENT_LABELS),
            "labels": ANNOUNCEMENT_LABELS,
            "description": "ê³µê³ ë¬¸ (ì˜ˆì‚°ê¸ˆì•¡, ë°œì£¼ê¸°ê´€, ì‚¬ì—…ë‚´ìš© ë“±)"
        },
        "pitch_deck": {
            "count": len(PITCH_DECK_LABELS),
            "labels": PITCH_DECK_LABELS,
            "description": "í”¼ì¹­ ìë£Œ (ì œí’ˆ, ì‹œì¥, íŒ€, ì¬ë¬´, ê²½ìŸì‚¬ ë“±)"
        },
        "ir_deck": {
            "count": len(IR_DECK_LABELS),
            "labels": IR_DECK_LABELS,
            "description": "IR ìë£Œ (ë§¤ì¶œ, ì˜ì—…ì´ìµ, TAM/SAM/SOM ë“±)"
        }
    }
    
    if doc_type:
        return info.get(doc_type.lower().replace("_", ""), info)
    
    return info


def load_docai_json(path: str) -> Dict:
    """Document AI JSON ë¡œë“œ"""
    return read_json(path)


def convert_bounding_poly(bounding_poly: Dict, width: int, height: int) -> List[int]:
    """Document AI boundingPoly â†’ LayoutLM normalized bbox (0-1000)"""
    
    if "normalizedVertices" in bounding_poly:
        verts = bounding_poly["normalizedVertices"]
        xs = [v.get("x", 0) * 1000 for v in verts]
        ys = [v.get("y", 0) * 1000 for v in verts]
    elif "vertices" in bounding_poly:
        verts = bounding_poly["vertices"]
        xs = [v.get("x", 0) / width * 1000 for v in verts]
        ys = [v.get("y", 0) / height * 1000 for v in verts]
    else:
        return [0, 0, 0, 0]
    
    return [
        int(min(xs)),
        int(min(ys)),
        int(max(xs)),
        int(max(ys)),
    ]


def extract_text_from_segment(full_text: str, segment: Dict) -> str:
    """textAnchor segmentì—ì„œ ì‹¤ì œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    
    start = int(segment.get("startIndex", 0))
    end = int(segment.get("endIndex", 0))
    return full_text[start:end].strip()


def prepare_layoutlm_input(
    doc_json: Dict,
    pdf_path: str,
    processor,
    max_length: int = 512
) -> Dict:
    """Document AI JSON + PDF â†’ LayoutLMv3 ì…ë ¥ í…ì„œ"""
    
    pages = doc_json.get("pages", [])
    if not pages:
        raise ValueError("âŒ OCR JSONì— pagesê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    full_text = doc_json.get("text", "")
    
    print(f"ğŸ“„ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘...")
    images = convert_from_path(pdf_path)
    
    if len(images) != len(pages):
        print(f"âš ï¸ ê²½ê³ : PDF í˜ì´ì§€ ìˆ˜({len(images)})ì™€ OCR í˜ì´ì§€ ìˆ˜({len(pages)})ê°€ ë‹¤ë¦…ë‹ˆë‹¤.")
    
    all_page_tokens: List[List[str]] = []
    all_page_boxes: List[List[List[int]]] = []
    all_page_images: List = []
    
    for idx, page in enumerate(pages):
        dim = page.get("dimension", {})
        width = dim.get("width", 1)
        height = dim.get("height", 1)
        
        page_tokens = []
        page_boxes = []
        
        for block in page.get("blocks", []):
            block_layout = block.get("layout", {})
            block_text_anchor = block_layout.get("textAnchor", {})
            block_bbox = block_layout.get("boundingPoly")
            
            if not block_bbox:
                continue
            
            if "paragraphs" in block and block.get("paragraphs"):
                for paragraph in block.get("paragraphs", []):
                    para_layout = paragraph.get("layout", {})
                    para_text_anchor = para_layout.get("textAnchor", {})
                    para_bbox = para_layout.get("boundingPoly")
                    
                    if not para_bbox:
                        continue
                    
                    for segment in para_text_anchor.get("textSegments", []):
                        text = extract_text_from_segment(full_text, segment)
                        
                        if not text or text.isspace():
                            continue
                        
                        words = text.split()
                        norm_bbox = convert_bounding_poly(para_bbox, width, height)
                        
                        for word in words:
                            if word.strip():
                                page_tokens.append(word)
                                page_boxes.append(norm_bbox)
            else:
                for segment in block_text_anchor.get("textSegments", []):
                    text = extract_text_from_segment(full_text, segment)
                    
                    if not text or text.isspace():
                        continue
                    
                    words = text.split()
                    norm_bbox = convert_bounding_poly(block_bbox, width, height)
                    
                    for word in words:
                        if word.strip():
                            page_tokens.append(word)
                            page_boxes.append(norm_bbox)
        
        all_page_tokens.append(page_tokens)
        all_page_boxes.append(page_boxes)
        
        if idx < len(images):
            all_page_images.append(images[idx])
        else:
            all_page_images.append(images[-1])
    
    total_tokens = sum(len(t) for t in all_page_tokens)
    print(f"\nğŸ” ì „ì²˜ë¦¬ ê²°ê³¼:")
    print(f"  - í˜ì´ì§€ ìˆ˜: {len(all_page_images)}")
    print(f"  - ì´ í† í° ìˆ˜: {total_tokens}")
    
    if total_tokens > 0:
        print(f"  - ì²« í˜ì´ì§€ í† í° ìƒ˜í”Œ: {all_page_tokens[0][:10]}")
        print(f"  - ì²« í˜ì´ì§€ bbox ìƒ˜í”Œ: {all_page_boxes[0][:2]}")
    else:
        print("  âš ï¸ ê²½ê³ : ì¶”ì¶œëœ í† í°ì´ ì—†ìŠµë‹ˆë‹¤!")
    
    print(f"\nğŸ¤– LayoutLM Processor ì¸ì½”ë”© ì¤‘...")
    encoding = processor(
        images=all_page_images,
        text=all_page_tokens,
        boxes=all_page_boxes,
        return_tensors="pt",
        padding="max_length",
        truncation=True,
        max_length=max_length,
    )
    
    print(f"  âœ… ì¸ì½”ë”© ì™„ë£Œ")
    print(f"  - input_ids shape: {encoding['input_ids'].shape}")
    print(f"  - bbox shape: {encoding['bbox'].shape}")
    print(f"  - pixel_values shape: {encoding['pixel_values'].shape}\n")
    
    return encoding


def print_label_statistics():
    """ë¼ë²¨ í†µê³„ ì¶œë ¥"""
    
    print("\n" + "=" * 80)
    print("ğŸ“Š ë¼ë²¨ ì‹œìŠ¤í…œ í†µê³„")
    print("=" * 80)
    
    info = get_label_info()
    
    total_labels = sum(v["count"] for v in info.values())
    print(f"\nâœ… ì „ì²´ ë¼ë²¨ ìˆ˜: {total_labels}ê°œ")
    
    print(f"\nğŸ“‹ ë¬¸ì„œ íƒ€ì…ë³„:")
    for doc_type, data in info.items():
        print(f"  {doc_type:15s}: {data['count']:3d}ê°œ - {data['description']}")
    
    print("\n" + "=" * 80)