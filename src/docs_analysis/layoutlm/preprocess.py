# src/docs_analysis/layoutlm/preprocess.py

import os
from typing import Dict, List, Tuple, Any
from pdf2image import convert_from_path
from src.utils.io_utils import read_json

# -------------------------------------------------------------------------
# 1. ë¼ë²¨ ì •ì˜ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
# -------------------------------------------------------------------------
ANNOUNCEMENT_LABELS = [
    "O",
    "B-ê³µê³ ì œëª©", "I-ê³µê³ ì œëª©", "B-ê³µê³ ë²ˆí˜¸", "I-ê³µê³ ë²ˆí˜¸",
    "B-ì˜ˆì‚°ê¸ˆì•¡", "I-ì˜ˆì‚°ê¸ˆì•¡", "B-ë°œì£¼ê¸°ê´€", "I-ë°œì£¼ê¸°ê´€",
    "B-ì‚¬ì—…ë‚´ìš©", "I-ì‚¬ì—…ë‚´ìš©", "B-ê³„ì•½ê¸°ê°„", "I-ê³„ì•½ê¸°ê°„",
    "B-ì œì¶œë§ˆê°", "I-ì œì¶œë§ˆê°",
]

PITCH_DECK_LABELS = [
    "O",
    "B-íšŒì‚¬ëª…", "I-íšŒì‚¬ëª…", "B-ìŠ¬ë¡œê±´", "I-ìŠ¬ë¡œê±´",
    "B-ëŒ€í‘œì", "I-ëŒ€í‘œì", "B-ì—°ë½ì²˜", "I-ì—°ë½ì²˜",
    "B-ì œí’ˆëª…", "I-ì œí’ˆëª…", "B-ì œí’ˆì„¤ëª…", "I-ì œí’ˆì„¤ëª…",
    "B-í•µì‹¬ê¸°ëŠ¥", "I-í•µì‹¬ê¸°ëŠ¥", "B-íŠ¹ì¥ì ", "I-íŠ¹ì¥ì ",
    "B-ê°€ê²©", "I-ê°€ê²©", "B-ì‹œì¥ê·œëª¨", "I-ì‹œì¥ê·œëª¨",
    "B-ì„±ì¥ë¥ ", "I-ì„±ì¥ë¥ ", "B-íƒ€ê²Ÿì‹œì¥", "I-íƒ€ê²Ÿì‹œì¥",
    "B-ì‹œì¥íŠ¸ë Œë“œ", "I-ì‹œì¥íŠ¸ë Œë“œ", "B-ê·œì œì •ë³´", "I-ê·œì œì •ë³´",
    "B-ë§¤ì¶œì•¡", "I-ë§¤ì¶œì•¡", "B-íˆ¬ìê¸ˆì•¡", "I-íˆ¬ìê¸ˆì•¡",
    "B-ë¹„ìš©", "I-ë¹„ìš©", "B-ê°€ê²©ì •ì±…", "I-ê°€ê²©ì •ì±…",
    "B-ê¸°ìˆ ëª…", "I-ê¸°ìˆ ëª…", "B-ê¸°ìˆ ì„¤ëª…", "I-ê¸°ìˆ ì„¤ëª…",
    "B-íŠ¹í—ˆ", "I-íŠ¹í—ˆ", "B-ê¸°ìˆ í‚¤ì›Œë“œ", "I-ê¸°ìˆ í‚¤ì›Œë“œ",
    "B-íŒ€ì›ëª…", "I-íŒ€ì›ëª…", "B-ì§ì±…", "I-ì§ì±…", "B-ê²½ë ¥", "I-ê²½ë ¥",
    "B-ê³ ê°ì‚¬", "I-ê³ ê°ì‚¬", "B-íŒŒíŠ¸ë„ˆì‚¬", "I-íŒŒíŠ¸ë„ˆì‚¬", "B-ì œíœ´", "I-ì œíœ´",
    "B-ê²½ìŸì‚¬ëª…", "I-ê²½ìŸì‚¬ëª…", "B-ê²½ìŸìš°ìœ„", "I-ê²½ìŸìš°ìœ„", "B-ì°¨ë³„ì ", "I-ì°¨ë³„ì ",
    "B-ë¬¸ì œì ", "I-ë¬¸ì œì ", "B-ì†”ë£¨ì…˜", "I-ì†”ë£¨ì…˜", "B-ë°°ê²½", "I-ë°°ê²½", "B-ë¹„ì „", "I-ë¹„ì „",
    "B-ë‚ ì§œ", "I-ë‚ ì§œ", "B-ê¸°ê°„", "I-ê¸°ê°„", "B-ë§ˆì¼ìŠ¤í†¤", "I-ë§ˆì¼ìŠ¤í†¤", "B-ì—°í˜", "I-ì—°í˜",
    "B-í†µê³„ìˆ˜ì¹˜", "I-í†µê³„ìˆ˜ì¹˜",
]

IR_DECK_LABELS = [
    "O",
    "B-íšŒì‚¬ëª…", "I-íšŒì‚¬ëª…", "B-ì„¤ë¦½ì¼", "I-ì„¤ë¦½ì¼", "B-ëŒ€í‘œì", "I-ëŒ€í‘œì",
    "B-ì‚¬ì—…ì˜ì—­", "I-ì‚¬ì—…ì˜ì—­", "B-ì œí’ˆëª…", "I-ì œí’ˆëª…",
    "B-ë§¤ì¶œì•¡", "I-ë§¤ì¶œì•¡", "B-ì˜ì—…ì´ìµ", "I-ì˜ì—…ì´ìµ", "B-ìˆœì´ìµ", "I-ìˆœì´ìµ",
    "B-íˆ¬ìê¸ˆì•¡", "I-íˆ¬ìê¸ˆì•¡", "B-íˆ¬ìì", "I-íˆ¬ìì",
    "B-ì‹œì¥ê·œëª¨", "I-ì‹œì¥ê·œëª¨", "B-TAM", "I-TAM", "B-SAM", "I-SAM", "B-SOM", "I-SOM",
    "B-ê¸°ìˆ ì—­ëŸ‰", "I-ê¸°ìˆ ì—­ëŸ‰", "B-íŠ¹í—ˆ", "I-íŠ¹í—ˆ", "B-R&D", "I-R&D",
    "B-íŒ€ì›ëª…", "I-íŒ€ì›ëª…", "B-ì§ì±…", "I-ì§ì±…", "B-ê²½ë ¥", "I-ê²½ë ¥", "B-í•™ë ¥", "I-í•™ë ¥",
    "B-ê³ ê°ì‚¬", "I-ê³ ê°ì‚¬", "B-ì‚¬ìš©ììˆ˜", "I-ì‚¬ìš©ììˆ˜",
    "B-í†µê³„ìˆ˜ì¹˜", "I-í†µê³„ìˆ˜ì¹˜",
]

# -------------------------------------------------------------------------
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# -------------------------------------------------------------------------

def get_labels(doc_type: str) -> List[str]:
    doc_type = doc_type.lower()
    if doc_type in ["announcement", "notice"]: return ANNOUNCEMENT_LABELS
    elif doc_type in ["pitch_deck", "pitch"]: return PITCH_DECK_LABELS
    elif doc_type in ["ir_deck", "ir"]: return IR_DECK_LABELS
    else: return PITCH_DECK_LABELS

def get_label_info(doc_type: str = None) -> Dict:
    info = {
        "announcement": {"count": len(ANNOUNCEMENT_LABELS), "labels": ANNOUNCEMENT_LABELS},
        "pitch_deck": {"count": len(PITCH_DECK_LABELS), "labels": PITCH_DECK_LABELS},
        "ir_deck": {"count": len(IR_DECK_LABELS), "labels": IR_DECK_LABELS}
    }
    if doc_type: return info.get(doc_type.lower().replace("_", ""), info)
    return info

def load_docai_json(path: str) -> Dict:
    return read_json(path)

def clamp(val, min_val, max_val):
    return max(min_val, min(val, max_val))

def convert_bounding_poly(bounding_poly: Dict, width: int, height: int) -> List[int]:
    """ì¢Œí‘œ ë³€í™˜ ë° 0~1000 ë²”ìœ„ í´ë¨í•‘ (LayoutLM í•„ìˆ˜)"""
    if "normalizedVertices" in bounding_poly:
        verts = bounding_poly["normalizedVertices"]
        xs = [v.get("x", 0) * 1000 for v in verts]
        ys = [v.get("y", 0) * 1000 for v in verts]
    elif "vertices" in bounding_poly:
        verts = bounding_poly["vertices"]
        xs = [v.get("x", 0) / width * 1000 for v in verts]
        ys = [v.get("y", 0) / height * 1000 for v in verts]
    else:
        return [0, 0, 0, 0]
    
    return [
        int(clamp(min(xs), 0, 1000)),
        int(clamp(min(ys), 0, 1000)),
        int(clamp(max(xs), 0, 1000)),
        int(clamp(max(ys), 0, 1000)),
    ]

def extract_text_from_segment(full_text: str, segment: Dict) -> str:
    start = int(segment.get("startIndex", 0))
    end = int(segment.get("endIndex", 0))
    if start >= len(full_text): return "" 
    return full_text[start:end].strip()

# -------------------------------------------------------------------------
# 3. í•µì‹¬ ì „ì²˜ë¦¬ ë¡œì§ (ì—ëŸ¬ ìˆ˜ì • ì™„ë£Œ)
# -------------------------------------------------------------------------

def prepare_layoutlm_input(
    doc_json: Dict,
    pdf_path: str,
    processor,
    max_length: int = 512
) -> Dict:
    """Document AI JSON + PDF â†’ LayoutLMv3 ì…ë ¥ í…ì„œ"""
    
    pages = doc_json.get("pages", [])
    if not pages:
        raise ValueError("âŒ OCR JSONì— pagesê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    full_text = doc_json.get("text", "")
    
    print(f"ğŸ“„ PDF â†’ ì´ë¯¸ì§€ ë³€í™˜ ì¤‘...")
    try:
        images = convert_from_path(pdf_path)
    except Exception as e:
        print(f"âš ï¸ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨ (Poppler í™•ì¸ í•„ìš”): {e}")
        # ì‹¤íŒ¨ ì‹œ ë¹ˆ ì´ë¯¸ì§€ ìƒì„± (ì½”ë“œ ì¤‘ë‹¨ ë°©ì§€)
        from PIL import Image
        images = [Image.new('RGB', (100, 100)) for _ in range(len(pages))]

    # ì´ë¯¸ì§€ ëª¨ë“œ ë³€í™˜ (RGB ê°•ì œ)
    images = [img.convert("RGB") for img in images]
    
    all_page_tokens = []
    all_page_boxes = []
    all_page_images = []
    
    # í˜ì´ì§€ ì²˜ë¦¬ ë£¨í”„
    loop_count = min(len(pages), len(images))
    
    for idx in range(loop_count):
        page = pages[idx]
        image = images[idx]
        dim = page.get("dimension", {})
        width = dim.get("width", 1)
        height = dim.get("height", 1)
        
        page_tokens = []
        page_boxes = []
        
        # ë¸”ë¡ ë‹¨ìœ„ íŒŒì‹±
        for block in page.get("blocks", []):
            block_layout = block.get("layout", {})
            block_bbox = block_layout.get("boundingPoly")
            
            # í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ ë¡œì§
            segments_to_process = []
            if "paragraphs" in block:
                for para in block["paragraphs"]:
                    segments_to_process.extend(para.get("layout", {}).get("textAnchor", {}).get("textSegments", []))
                    # paragraph bboxê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ block bbox ì‚¬ìš©
                    current_bbox = para.get("layout", {}).get("boundingPoly", block_bbox)
            else:
                segments_to_process = block_layout.get("textAnchor", {}).get("textSegments", [])
                current_bbox = block_bbox
            
            if not current_bbox: continue
            
            # í…ìŠ¤íŠ¸ì™€ ì¢Œí‘œ ë§¤í•‘
            for segment in segments_to_process:
                text = extract_text_from_segment(full_text, segment)
                if not text or text.isspace(): continue
                
                norm_bbox = convert_bounding_poly(current_bbox, width, height)
                
                # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ìª¼ê°œì„œ ì¶”ê°€
                for word in text.split():
                    if word.strip():
                        page_tokens.append(word)
                        page_boxes.append(norm_bbox)
        
        # ğŸ”¥ [í•µì‹¬ ìˆ˜ì •] ë¹ˆ í˜ì´ì§€(í…ìŠ¤íŠ¸ ì—†ëŠ” ìŠ¬ë¼ì´ë“œ) ì²˜ë¦¬
        # ì´ê²Œ ì—†ìœ¼ë©´ Processorê°€ í…ì„œë¥¼ ë§Œë“¤ë‹¤ê°€ ë©ˆì¶¥ë‹ˆë‹¤.
        if not page_tokens:
            # print(f"  âš ï¸ {idx+1}í˜ì´ì§€ëŠ” í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. (Empty Placeholder ì¶”ê°€)")
            page_tokens = ["<IMAGE>"]
            page_boxes = [[0, 0, 0, 0]]
        
        all_page_tokens.append(page_tokens)
        all_page_boxes.append(page_boxes)
        all_page_images.append(image)
    
    print(f"\nğŸ” ì „ì²˜ë¦¬ ì™„ë£Œ:")
    print(f"  - ì´ í˜ì´ì§€: {len(all_page_images)}")
    print(f"  - ì´ í† í° ìˆ˜: {sum(len(t) for t in all_page_tokens)}")
    
    print(f"\nğŸ¤– LayoutLM Encoding (Padding=True)...")
    
    # ğŸ”¥ Processor í˜¸ì¶œ (ì•ˆì „ì¥ì¹˜ í¬í•¨)
    try:
        encoding = processor(
            images=all_page_images,
            text=all_page_tokens,
            boxes=all_page_boxes,
            return_tensors="pt",
            padding="max_length",  # ë°°ì¹˜ ì²˜ë¦¬ ì‹œ í•„ìˆ˜
            truncation=True,
            max_length=max_length
        )
        return encoding
        
    except Exception as e:
        print(f"âŒ Processor Encoding ì˜¤ë¥˜: {e}")
        raise e

def print_label_statistics():
    pass